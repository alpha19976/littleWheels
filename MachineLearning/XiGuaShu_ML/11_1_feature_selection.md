# 特征选择
## 特征
* 特征(feature)：样本的属性
* 相关特征(relevant feature)：对当前学习任务有用的属性
 * 学习任务不同，则相关特征很可能不同
* 无关特征(irrelevant feature)：对当前学习任务没有用的属性
* 冗余特征(redundant feature):包含的信息能从其它特征中推演出来
 * 长、宽 => 面积
 * 表达了一种中间概念，可能是有用的
 * 西瓜书暂不考虑冗余特征

## 特征选择
* 特征选择(feature selection)
 * 从特征集合中选择出相关特征的过程
* 特征选择是数据预处理(data preprocessing)中的一个重要过程
* 特征选择和降维是处理高纬数据的两大主流技术
* 解决两个问题
 * 维数灾难问题(高维数据导致样本稀疏，导致距离计算困难)
 * 降低学习任务的难度(高维数据提高了存储和计算的难度)

## 特征选择的两个环节
### 子集搜索(subset search)
三种贪心策略

##### 前向搜索(forward)
从空集合开始，逐渐尝试增加相关特征
* S_sel是已经选择的特征，S_rem是还未被选择的特征
* P(S)是对特征集合S的子集评价
* 对S_rem中的每个特征f
 * 计算S_sel + f后的子集评价P(S_sel + f)，得到P(S_sel + f)最大的特征f_max
 * 如果P(S_sel + f_max) > P(S_sel)，则将f_max加到S_sel，将f_max从S_rem移除
 * 如果P(S_sel + f_max) <= P(S_sel)，则特征选择停止

##### 后向搜索(backward)
从所有特征集合开始，逐渐尝试去掉无关特征。去掉某个特征，对子集评价的性能无影响或者提升最大，于是就去掉这个特征

##### 双向搜索(bidirectional)
从所有特征集合开始，每一轮，既尝试减少无关特征，又尝试增加相关特征（确定不会被去掉的特征）

### 子集评价(subset evaluation)
