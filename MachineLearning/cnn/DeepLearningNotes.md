* 神经网络中调节参数的原理是梯度下降，需要用到损失函数对每个参数的倒数
 * 利用倒数去作为更新参数的量度
* 梯度下降需要计算损失函数对每个参数的偏导
* 倒数在网络结构中具有前向传播、后向传播的性质，[参见Calculus on Computational Graphs: Backpropagation](http://colah.github.io/posts/2015-08-Backprop/)
 * 前向传播：某个变量的变化对后面与之关联的每个变量的的变化的影响
 * 后向传播：前面某个变量的的倒数可以用后面某个变量的导师间接求得（全倒数公式和链式法则）
 * 前向传播解释了前面某个变量对之后节点的影响
 * 后向传播提供了一种快速求解导数的方法
* 后向传播算法的计算效率的提升可以用算法中的Dynamic Programming来解释，即后向传播算法是一种DP算法
* 全倒数公式和链式法则：连线相乘, 分叉相加, 单路全导, 叉路偏导


