## 模型
### 逻辑回归
* [并行逻辑回归项目](https://github.com/strint/DML/tree/master/logistic_regression)
* [LogisticRegression_OWLQN_Notes](https://github.com/strint/LogisticRegression_OWLQN_Notes)：
逻辑回归和OWLQN优化算法学习笔记，这个笔记围绕Galen Andrew and Jianfeng Gao. 2007 这篇论文实现的代码来整理逻辑回归、OWLQN的原理和实现。

### 神经网络
* [Regularization of Big Neural Networks](https://www.youtube.com/watch?v=J24dYobuOsI),201408.
* [MIT的人工智能课中神经网络的章节](https://www.youtube.com/watch?v=q0pm3BrIUFo) 原理：这个视频讲的神经网络的方法很吸引人，讲了神经元，然后为神经元建模，做计算修改模型，最后分析利弊，展示了一个建模的完整过程，缺点是时间短，不是很深入，但是展示的过程很有启发性，讲述了创建方法的过程，而不是直接教授方法。201408.
* [Stanford 的机器学习和深度学习网站](http://ufldl.stanford.edu/wiki/index.php/Backpropagation_Algorithm),  实际应用：从公式到代码实现，比较接近实际开发,201408.
* 神经网络读书班，和Y春晖、L睿凡老师（认识了HeMeng）

### 矩阵分解
* Factorization Machines with libFM, Steffen Rendle, 一篇关于矩阵分解机的介绍文章，说明了矩阵分解机的目标函数、优化函数、求解方法，并讨论了矩阵分解同一些其它模型的对应关系, 201407.
* Matrix Factorization Techniques for Recommender Systems, Yehuda Koren and Robert Bell and Chris Volinsky, 一篇概述，介绍了矩阵分解应用于推荐系统的思路，比较全面但是不深入, 201407.

### GBDT

## 软件所机器学习读书会
### PRML
* PRML chapter 5: Neural Networks, C. M. Bishop, ljk读书会到此暂停，这一章的内容没有都读，但是核心的神经网络的概念通过看网络上的视频和教程搞明白了,201408.
* PRML chapter 4: Linear Models for Classification, C. M. Bishop, 软件所ljk读书会，跟着读书会每周看两节书，部分地方看懂了，但是没有后续的提问、思考、总结，所以没有整体掌握的感觉, 还有一个原因是第一二章节没有读完，导致读第三四章时欠缺基础知识，这个月把一二章也读了一半, 201407.
* PRML chapter 3: Linear Models for Regression, C. M. Bishop, 软件所ljk读书会，跟着读书会每周看两节书，部分地方看懂了，但是没有后续的提问、思考、总结，所以没有整体掌握的感觉, 201406.

### 西瓜书
